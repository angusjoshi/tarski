\section{The Arrival Problem}
The arrival problem is, given a directed graph with
a particular structure and designated source and target vertex,
decide whether or not a particular walk starting at the source
ever reaches the target. The beginnings of this section will be
in making this idea precise.
\begin{definition}[Arrival Graph]
  An \emph{arrival graph} is a set of vertices $V$, a pair of
  vertices $s, t \in V$, and a pair of maps 
  $s_0, s_1 : V \to V$. 
\end{definition}
\begin{definition}[Arrival Walk]
  Let $(V, s, t, s_0, s_1)$ be an arrival graph. The \emph{arrival walk}
  on this graph is a sequence of vertices $(v_i)_{i \in \znn} \in V$
  such that $v_0 = s$, and $v_{i+1} = 
  \begin{cases} 
    s_0(v_i), & \text{$n_i$ even}\\  
    s_1(v_i), & \text{$n_i$ odd},
  \end{cases}$
  where $n_i$ is the number of times $v_i$ has appeared previously in
  the sequence.
\end{definition}
 A diagram of an example arrival graph is shown in 
in $\cref{arrivalDiagram}$.
It is clear that the arrival walk for a particular arrival graph
is entirely defined by the structure of the graph, which is what
lead it to be called a zero player graph game in \citep{arrivalBasic}.
\begin{definition}[$\textsc{Arrival}$]
  The $\textsc{Arrival}$ problem is, given an arrival graph $(V, s, t, s_0, s_1)$,
  decide whether or not the arrival walk ever reaches $t$.
\end{definition}
\begin{figure}[h]
  \centering
  \input{diagrams/arrivalDiagram.tex}
  \caption{The goal of the arrival problem is to decide whether a partiular walk on a directed graph with a particular
  structure reaches the target. In this example,
  the arrival walk begins $s \to v_1 \to v_4 \to s \to v_3 \to \ldots$.} \label{arrivalDiagram}
\end{figure}
There is an obvious algorithm to solve the $\textsc{Arrival}$ problem;
just simulate the walk. Cases of instances where $t$ is not reachable pose a problem however -
the walk must cycle infinitely and never terminate!
The following content demonstrates that this is a non issue.
\begin{definition}[Hopeful and Desperation]
  Let $(V, s, t, s_0, s_1)$ be an instance of the $\arr$ problem. A vertex $v \in V$
  is \emph{hopeful} if there is a path $v \to t$ in the directed graph defined with
  the vertex set $V$ and edge set $E \subseteq V \times V$ with $(u, v) \in E$ if and
  only if either $s_0(u) = v$ or $s_1(u) = v$. The \emph{desperation} of a hopeful vertex
  $v$ is the length of the shortest path from $v$ to $t$.
\end{definition}
\begin{lemma}[\citep{arrivalBasic}]
  Let $(V, s, t, s_0, s_1)$  be an instance of the $\arr$ problem. If $v \in V$ is hopeful,
  the arrival walk passes through $v$ at most $2^{|V|}$ times.
\end{lemma}
\begin{proof}
  Begin by noting that if a vertex is hopeful, it's desperation is at most $|V|$. I perform
  an induction on the desperation of $v$. Suppose the desperation of $v \in V$ is 1. Then either
  $s_0(v) = t$ or $s_1(v) = t$. If $s_0(v) = t$, $t$ will be reached after passing through $v$ once.
  If $s_1(v) = t$ and $s_0(v) \neq t$ $t$ will be reached after passing through $v$ twice. In
  both cases $v$ is passed through at most $2^1 = 2$ times. \\
  Suppose that all hopeful vertices with desperation $d - 1$ are passed through at most $2^{d-1}$ times.
  Then if $v \in V$ is hopeful with desperation $d$, for some hopeful $w \in V$ with desperation
  $d - 1$ either $s_0(v) = w$ or $s_1(v) = w$. So at least every second passing of $v$, the
  walk will proceed to $w$. But the walk can pass through $w$ at most $2^{d-1}$ times,
  so the walk can pass through $v$ at most $2 \cdot 2^{d - 1} = 2^d$ times.
\end{proof}
\begin{cor}\label{walkFinite}
  Let $(V, s, t, s_0, s_1)$ be an instance of the $\arr$ problem. Then the arrival
  walk either reaches $t$, or reaches a vertex which is not hopeful.
\end{cor}
From \cref{walkFinite} it is clear that deciding an instance of the $\arr$ problem is
equivalent to deciding whether or not the arrival walk reaches $t$ or reaches a vertex which
is not hopeful.
\begin{definition}[Processed Arrival]
  Let $(V, s, t, s_0, s_1)$ be an instance of the arrival problem. Let
  $\sim$ be the equivalence relation on $V$ generated by $u \sim v$ if
  $u$ and $v$ are both not hopeful.
  The \emph{processed arrival problem}
  is a set of vertices $V' = V / \sim$, the canonical projections of $s, t, s_0, s_1$ into $V'$,
  and a choice of representative $\overline{t} \in V'$ of all the non hopeful vertices in $V$.
\end{definition}
Noting that the set of non hopeful vertices can be easily computed in linear time with a breadth first search
from $t$, from this point on I will refer
to instances of the $\arr$ problem exclusively as tuples $(V, s, t, \overline{t}, s_0, s_1)$ 
constructed as above.
\begin{cor}[\citep{arrivalBasic}]
  The time complexity of the $\arr$ problem is $O(n \cdot 2^n)$.
\end{cor}
\begin{proof}
  I reason that the arrival walk on the processed instance $(V, s, t, \overline{t}, s_0, s_1)$
  has it's walk length bounded by $O(n \cdot 2^n)$. Every vertex $v \in V$ with $v \neq \overline{t}$
  is hopeful with desperation at most $n$, so by \cref{walkFinite} can be passed through at most
  $2^{n}$ times. If the walk reaches $t$ or $\overline{t}$ it terminates, and there are at most
  $n$ vertices $w \in V$ such that $w \not\in \{t, \overline{t}\}$, so the walk can take at most
  $n \cdot 2^n$ steps.
\end{proof}
There are in fact instances of the $\arr$ problem with exponentially long walks -
as seen in \cref{expLongArrival} - implying that the worst-case runtime of this algorithm is exponential.
Recently a sub-exponential\footnote{Specifically an algorithm running
in time $O(2^{\sqrt{n}})$.} upper bound for $\arr$ was given in \citep{g√§rtner2021subexponential}.
Interestingly, their algorithm involves a reduction from $\arr$ to $\trsk$. I will not detail
the reduction used in the sub-exponential algorithm, but will spend the remainder of the section
demonstrating a similar, yet simpler reduction from $\arr$ to $\trsk$.
\begin{figure}
  \centering
  \input{diagrams/expLong.tex}
  \caption{There are instances of the arrival problem with exponentially long walks. In this example, if
  you consider the 'switch' at each node as a bit, the arrival walk is equivalent to counting from one up to $2^n$.}\label{expLongArrival}
\end{figure}
\newcommand{\fin}{f_{\text{in}}}
\begin{definition}[Switching Flow]
  Let $(V, s, t, \overline{t}, s_0, s_1)$ be an arrival graph. A \emph{switching flow} is a pair of maps 
  $f_0, f_1 : V \setminus \{t, \overline{t}\} \to \znn$ such that the following axioms hold.
    Let $\fin(v) =
        \sum_{\substack{w \in V \\ s_0(w) = v}} f_0(w) 
        + \sum_{\substack{w \in V \\ s_1(w) = v}} f_1(w)$. 
  \begin{itemize}
    \item For all $v \in V \setminus \{s, t, \overline{t}\}$, $\fin(v) = f_0(v) + f_1(v)$ (flow conservation),
    \item $\fin(s) = f_0(s) + f_1(s) - 1$ (source flow conservation),
    \item For all $v \in V$, $f_1(v) \leq f_0(v) \leq f_1(v) + 1$ (switching).
  \end{itemize}
\end{definition}
  It was observed in \citep{arrivalBasic} that the walk on an arrival graph can be characterized
  by a switching flow.
  \begin{lemma}[\citep{arrivalBasic}]\label{walkSwitching}
    Let $(V, s, t, \overline{t}, s_0, s_1)$ be an instance of the $\arr$ problem. Define
    $f_0 : V \setminus \{t, \overline{t}\} \to \znn$ by $f_0(v) =$ the number of times $s_0(v)$
    is traversed in the arrival walk, and define $f_1$ similarly. Then $(f_0, f_1)$ is a switching
    flow.
  \end{lemma}
  \begin{proof}
    Flow conservation and source flow conservation follow from the fact that the walk must walk
    out of a vertex if it walks in, minus the initial step it takes from the source. Switching
    follows from the nature of the walk taking the $s_0$ edge on even passes, and $s_1$ edge on odd
    passes.
  \end{proof}
  I next establish a correspondence from arrival instances to monotone functions.
  \begin{definition}[Arrival Monotone Function]
    Let $(V, s, t, \overline{t}, s_0, s_1)$ be an instance of the arrival problem,
    $d = |V \setminus \{t, \overline{t}\}|$ and
    $(v_i)_{i \in [d]}$ be an enumeration of the vertices in 
    $V \setminus \{t, \overline{t}\}$. The \emph{arrival monotone function} is a function
    $f : \znn^d \to \znn^d$ defined coordinatewise as,
  \begin{align*}
    f((a_1, ..., a_d))_i = \begin{cases}
    \sum_{\substack{j \in [d] \\ s_0(v_j) = v_i}} \left\lceil \frac{a_j}{2} \right\rceil
      + \sum_{\substack{j \in [d] \\ s_1(v_j) = v_i}} \left\lfloor \frac{a_j}{2} \right\rfloor
      & v_i \neq s \\
    1 + \sum_{\substack{j \in [d] \\ s_0(v_j) = v_i}} \left\lceil \frac{a_j}{2} \right\rceil
      + \sum_{\substack{j \in [d] \\ s_1(v_j) = v_i}} \left\lfloor \frac{a_j}{2} \right\rfloor
      & v_i = s.
    \end{cases}
  \end{align*}
  \end{definition}
  \begin{lemma}\label{arrMonotoneIsMonotone}
    The arrival monotone function is monotone.
  \end{lemma}
  \begin{proof}
    Clearly the sum of monotone functions is also monotone, $\lceil \cdot \rceil$ and $\lfloor \cdot \rfloor$
    are monotone, composition of monotone functions is monotone, linear functions with non-negative coefficients
    are monotone, and constant functions are monotone. This encompasses all components of the above function,
    which is therefore montone.
  \end{proof}
  The monotone function was constructed precisely so that the following proposition holds.
  \begin{prop}
    Let $f : \znn^d \to \znn^d$ be an arrival monotone function, and $a = (a_1, ..., a_d) \in \znn^d$. 
    Define $g_0(v_i) = \lceil \frac{a_i}{2} \rceil$ and $g_1(v_i) = \lfloor \frac{a_i}{2} \rfloor$. 
    Then $(g_0, g_1)$ is a switching flow if and only if $f(a) = a$.
  \end{prop}
  \begin{proof}
    $(\impliedby)$ For flow conservation, let $v_i \in V \setminus \{s, t, \overline{t}\}$. Then,
    \begin{align*}
      \sum_{\substack{j \in [d] \\ s_0(v_j) = v_i}} g_0(v_j) 
      + \sum_{\substack{j \in [d] \\ s_0(v_j) = v_i}} g_1(v_j) &= 
      \sum_{\substack{j \in [d] \\ s_0(v_j) = v_i}}  \left\lceil \frac{a_j}{2} \right\rceil
      + \sum_{\substack{j \in [d] \\ s_0(v_j) = v_i}} \left\lfloor \frac{a_j}{2} \right\rfloor \\
      &= f(a)_i \\ 
      &= a_i \\ 
      &= \left\lceil \frac{a_i}{2}\right\rceil + \left\lfloor \frac{a_i}{2}\right\rfloor \\
      &= g_0(v_i) + g_1(v_1).
    \end{align*}
    Source flow conservation follows similarly. Switching is clear from the definition of $\lfloor \cdot \rfloor$
    and $\lceil \cdot \rceil$. \\
    $(\implies)$ Let $g_0(v_i) = \left\lceil \frac{a_i}{2} \right\rceil$, 
    $g_1(v_i) = \left\lfloor \frac{a_i}{2} \right\rfloor$, and $(g_0, g_1)$ be a switching flow. Then
    for each $i \in [d]$ if $v_i \neq s$,
    \begin{align*}
      f((a_1, ..., a_d))_i &= 
    \sum_{\substack{j \in [d] \\ s_0(v_j) = v_i}} \left\lceil \frac{a_j}{2} \right\rceil
      + \sum_{\substack{j \in [d] \\ s_1(v_j) = v_i}} \left\lfloor \frac{a_j}{2} \right\rfloor \\
      &= \sum_{\substack{j \in [d] \\ s_0(v_j) = v_i}}  g_0(v_j) 
      + \sum_{\substack{j \in [d] \\ s_1(v_j) = v_i}}  g_1(v_j) \\
      &= g_0(v_i) + g_1(v_i) \qquad \text{(by flow conservation)} \\
      &= \left\lceil \frac{a_i}{2} \right\rceil + \left\lfloor \frac{a_i}{2} \right\rfloor = a_i,
    \end{align*}
    and if $v_i = s$,
    \begin{align*}
      f((a_1, ..., a_d))_i &= 
    1 + \sum_{\substack{j \in [d] \\ s_0(v_j) = v_i}} \left\lceil \frac{a_j}{2} \right\rceil
      + \sum_{\substack{j \in [d] \\ s_1(v_j) = v_i}} \left\lfloor \frac{a_j}{2} \right\rfloor \\
      &= 1 + \sum_{\substack{j \in [d] \\ s_0(v_j) = v_i}}  g_0(v_j) 
      + \sum_{\substack{j \in [d] \\ s_1(v_j) = v_i}}  g_1(v_j) \\
      &= 1 + g_0(v_i) + g_1(v_i) - 1 \qquad \text{(by source flow conservation)} \\
      &= \left\lceil \frac{a_i}{2} \right\rceil + \left\lfloor \frac{a_i}{2} \right\rfloor = a_i.
    \end{align*}
  \end{proof}
  The next proposition draws an intriguing connection between the arrival walk and monotone function.
  \newcommand{\lc}{\left\lceil}
  \newcommand{\rc}{\right\rceil}
  \newcommand{\lf}{\left\lfloor}
  \newcommand{\rf}{\right\rfloor}
  \begin{prop}
    Let $(V, s, t, \overline{t}, s_0, s_1)$ be an instance of the problem, and $f$ be the 
    arrival monotone function. For $a \in \znn^d$ let $g_0(a) = \lc \frac{a}{2} \rc$ and 
    $g_1(a) = \lf \frac{f(a)}{2} \rf$. Let 
    $(f_0^i : [d] \to \znn, f_1a^i : [d] \to znn)_{i \in znn}$
    be a sequence defined by $f_0^i(j) = $ the number of times the $s_0$ edge has been taken from $v_j$
    after $i$ steps in the walk, and define $f_1^i(j)$ similarly for the $s_1$ edge.
    by $f_0 = $ the number of times 
  \end{prop}
  So finding a switching flow can be reduced to finding a fixpoint of a particular monotone function.
  This doesn't quite fit into my definition of the $\trsk$ problem yet however, as that requires a finite
  lattice and $\znn^d$ is infinite. Fortunately this isn't an issue.
  \begin{notation}
    For $N \in \znn$ notation $[N]_0$ represents $[N] \cup \{0\}$.
  \end{notation}
  \newcommand{\no}{[N]_0}
  \begin{definition}[Bounded arrival monotone function]
    Let $(V, s, t, \overline{t}, s_0, s_1)$ be an instance of the arrival problem and $f$
    be it's corresponding arrival function. Let $n = |V|$ and $N = 2^n$. The \emph{bounded arrival monotone function}
    is a function $F : \no^d \to \no^d$ defined coordinatewise as $F(a)_i = \min(f(a)_i, N)$. 
  \end{definition}
  \begin{lemma}
    Let $F$ be a bounded arrival monotone function. Then $F$ is monotone.
  \end{lemma}
  \begin{proof}
    Similarly to the proof of \cref{arrMonotoneIsMonotone}, $\min(\cdot, \; N)$ is clearly monotone.
    Monotonicity then follows monotonicity of the arrival monotone function, and monotonicity
    being preserved under composition.
  \end{proof}
  \begin{lemma}\label{upOne}
    Let $f : \znn^d \to \znn^d$ be a monotone arrival function. If $a \in \znn^d$ then
    $\sum_{i \in [d]} f(a)_i \leq 1 + \sum_{i \in [d]} a_i$.
  \end{lemma}
  \begin{proof}
    I have 
    \begin{align*}
      \sum_{i \in [d]} f_i ((a_1, ..., a_d)) &= \sum_{i \in [d]} \begin{cases}
    \sum_{\substack{j \in [d] \\ s_0(v_j) = v_i}} \left\lceil \frac{a_j}{2} \right\rceil
      + \sum_{\substack{j \in [d] \\ s_1(v_j) = v_i}} \left\lfloor \frac{a_j}{2} \right\rfloor
      & v_i \neq s \\
    1 + \sum_{\substack{j \in [d] \\ s_0(v_j) = v_i}} \left\lceil \frac{a_j}{2} \right\rceil
      + \sum_{\substack{j \in [d] \\ s_1(v_j) = v_i}} \left\lfloor \frac{a_j}{2} \right\rfloor
      & v_i = s 
    \end{cases}\\
        &= 1 + \sum_{i \in [d]} \sum_{\substack{j \in [d] \\ s_0(v_j) = v_i}}  \left\lceil \frac{a_j}{2} \right\rceil
      + \sum_{i \in [d]} \sum_{\substack{j \in [d] \\ s_1(v_j) = v_i}} \left\lfloor \frac{a_j}{2} \right\rfloor. \\
    \end{align*}
    By construction of $s_0$ and $s_1$, for each $j \in [d]$ there is at most one
    $i \in [d]$ such that $s_0(v_j) = v_i$ and at most one $i' \in [d]$ such that $s_1(v_j) = v_{i'}$.
    So,
    \begin{align*}
        1 + \sum_{i \in [d]} \sum_{\substack{j \in [d] \\ s_0(v_j) = v_i}}  \left\lceil \frac{a_j}{2} \right\rceil
      + \sum_{i \in [d]} \sum_{\substack{j \in [d] \\ s_1(v_j) = v_i}} \left\lfloor \frac{a_j}{2} \right\rfloor
      &\leq 1 + \sum_{j \in [d]} \left\lceil \frac{a_j}{2} \right\rceil + \sum_{j \in [d]} \left\lfloor \frac{a_j}{2} \right\rfloor \\
      &= 1 + \sum_{i \in [d]} a_i. 
    \end{align*}
  \end{proof}
  \begin{lemma}[\citep{g√§rtner2021subexponential}]
    Let $(V, s, t, \overline{t}, s_0, s_1)$ be an instance of the arrival problem, 
    $n = |V|$, $N = 2^n$, $d = |V \setminus \{t, \overline{t}\}|$, 
    $f : \znn^d \to \znn^d$ be the arrival monotone function, and $F : \no^d \to \no^d$
    be the bounded arrival monotone function.
    If $a \in \no^d$ satisfies $F(a) = a$, then $f(a) = a$. 
  \end{lemma}
  \begin{proof}
    Begin by noting that for all $a \in \no^d$, $f(a) \geq F(a)$. It follows that if $f(a) \neq F(a)$ then
    $F(a) > f(a)$. From \cref{upOne} combined with the fact that $F(a) = a$, I find that 
    $\sum_{i \in [d]} f(a)_i = 1 + \sum_{i \in [d]} a_i$. But for all $i \in [d]$, $f(a)_i \geq a_i$,
    so it must be the case that for some $i \in [d]$, $f(a)_j = 
    \begin{cases} a_j + 1 & j = i \\ a_j & j \neq i. \end{cases}$. By definition $F(a)_j = \min(f(a)_j, N)$.
      Since $a$ was a fixpoint of $F$, $a_j = \min(f(a)_j, N) = N$, and $f(a)_j = a_j + 1$.
    For $\sum_{i \in [d]} f(a)_i = 1 + \sum_{i \in [d]} a_i$ I require that $f_{\text{in}}(t) = 0$ and $f_{\text{in}}(\overline{t}) = 0$.
  \end{proof}
  So I've proven that finding switching flows is reducible to $\trsk$. The last step is to show that
  finding a switching flow gives me the answer to the $\trsk$ problem.
